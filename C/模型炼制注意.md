---
tags:- AI绘画
- AI
- 模型炼制
- 摘录
---

 损失函数描述 AI 学习到的东西和实际产生的东西的偏差值叫损失值 loss，利用偏差值可以指导 AI 的学习方向，去优化 AI 模型中的参数。损失函数利用梯度下降逐渐向下走是 AI 学习的过程，走到图像最低点时是最优解。梯度下降指导 AI 学习走的方向/下坡方向，根据损失值给出的训练数据权值计算出来的，就涉及数据量的问题。小批量梯度下降算法/batch-size 一种梯度下降算法，小批量的计算也就是 batch-size，决定了一次选取多少图来计算梯度，比如训练有1万张图，batch-size 为3，计算一次梯度是从1万张里面选三张随机的图来计算，就不用一次计算全部图。调整 batch-size 值时要调整学习率，需要同时乘以相同值。epoch 代表过了1遍训练集内所有的样本。学习率损失函数走的步数。学习率小，步子小容易找到最低点，但非常慢同时容易卡在图像上不同起伏里；学习率大，快速跑完，丢失最低点。学习率最好是变动的，先大后小。